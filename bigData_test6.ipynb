{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded............\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = pd.read_excel(\"orderslist.xlsx\", sheet_name=\"Sheet1\", engine='openpyxl')\n",
    "\n",
    "print(\"Data Loaded............\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['ship_date'] = pd.to_datetime(data['ship_date'])\n",
    "\n",
    "\n",
    "data['week'] = data['ship_date'].dt.strftime('%Y-%U')\n",
    "\n",
    "\n",
    "def categorize_gallons(gallons):\n",
    "    if gallons <= 100:\n",
    "        return '0-100'\n",
    "    \n",
    "    elif gallons <= 150:\n",
    "        return '100-150'\n",
    "    \n",
    "    elif gallons <= 330:\n",
    "        return '150-330'\n",
    "    elif gallons <= 550:\n",
    "        return '330-550'\n",
    "    elif gallons <= 1000:\n",
    "        return '550-1000'\n",
    "    elif gallons <= 3000:\n",
    "        return '1000-3000'\n",
    "    else:\n",
    "        return 'greater_than_3000'\n",
    "\n",
    "data['gallon_range'] = data['gallons_shipped'].apply(categorize_gallons)\n",
    "\n",
    "\n",
    "pivot_data = data.pivot_table(index=['whse', 'week'], columns='gallon_range', values='route', aggfunc='count', fill_value=0)\n",
    "\n",
    "\n",
    "\n",
    "# Output Data: 2023/08/18\n",
    "\n",
    "#pivot_data.to_excel('2023_08_18_Task01_galloons_ranges_weekly_analyse_.xlsx')\n",
    "\n",
    "#update requested ---> 2023/08/21\n",
    "pivot_data.to_excel('2023_08_21_Task01_galloons_ranges_weekly_analyse_.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorize_gallons(gallons):\n",
    "    \n",
    "    if gallons <= 100:\n",
    "        return '0-100'\n",
    "    \n",
    "    elif gallons <= 150:\n",
    "        return '100-150'\n",
    "\n",
    "    elif gallons <= 330:\n",
    "        return '150-330'\n",
    "    elif gallons <= 550:\n",
    "        return '330-550'\n",
    "    elif gallons <= 1000:\n",
    "        return '550-1000'\n",
    "    elif gallons <= 3000:\n",
    "        return '1000-3000'\n",
    "    else:\n",
    "        return 'greater_than_3000'\n",
    "\n",
    "data['gallon_range'] = data['gallons_shipped'].apply(categorize_gallons)\n",
    "\n",
    "\n",
    "pivot_data = data.pivot_table(index='whse', columns='gallon_range', values='route', aggfunc='count', fill_value=0)\n",
    "\n",
    "# Save the pivoted data to an Excel file\n",
    "#pivot_data.to_excel('2023_08_18_Task01_gallons_overall.xlsx')\n",
    "\n",
    "\n",
    "#update requested ---> 2023/08/21\n",
    "pivot_data.to_excel('2023_08_21_Task01_gallons_overall.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data['ship_date'] = pd.to_datetime(data['ship_date'])\n",
    "\n",
    "\n",
    "data['day_of_week'] = data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "pivot_data = data.pivot_table(index=['whse'], columns='day_of_week', values='gallons_shipped', aggfunc='mean', fill_value=0)\n",
    "\n",
    "# Reorder the columns to match the desired day order\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "pivot_data = pivot_data[desired_day_order]\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task02_daily_avg_galloon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f4ede16f8204>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
      "<ipython-input-6-f4ede16f8204>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bulk_data = data[data['product_type'] == 'BULK']\n",
    "\n",
    "\n",
    "\n",
    "bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
    "\n",
    "\n",
    "bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "pivot_data = bulk_data.pivot_table(index=['whse'], columns='day_of_week', values='gallons_shipped', aggfunc='mean', fill_value=0)\n",
    "\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "pivot_data = pivot_data[desired_day_order]\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task02_daily_bulk_avg_galloon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6a8c1c1e0c30>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
      "<ipython-input-7-6a8c1c1e0c30>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bulk_data = data[data['product_type'] == 'PACKAGE']\n",
    "\n",
    "\n",
    "\n",
    "bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
    "\n",
    "\n",
    "bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "pivot_data = bulk_data.pivot_table(index=['whse'], columns='day_of_week', values='gallons_shipped', aggfunc='mean', fill_value=0)\n",
    "\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "pivot_data = pivot_data[desired_day_order]\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task02_daily_package_avg_galloon.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data['ship_date'] = pd.to_datetime(data['ship_date'])\n",
    "\n",
    "\n",
    "data['day_of_week'] = data['ship_date'].dt.day_name()\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "data_filtered = data[data['day_of_week'].isin(desired_day_order)]\n",
    "\n",
    "\n",
    "\n",
    "pivot_data = data_filtered.pivot_table(index=['whse', 'day_of_week'], values='product_id', aggfunc='nunique')\n",
    "\n",
    "\n",
    "average_unique_products = pivot_data.groupby(['whse', 'day_of_week']).mean()\n",
    "\n",
    "\n",
    "average_unique_products = average_unique_products.reset_index()\n",
    "\n",
    "\n",
    "result_pivot = average_unique_products.pivot(index='whse', columns='day_of_week', values='product_id')\n",
    "\n",
    "\n",
    "result_pivot.to_excel('2023_08_18_Task03_average_unique_products_ids_per_day_per_warehouse.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-6514019789f9>:8: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  data['week_number'] = data['ship_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "data['ship_date'] = pd.to_datetime(data['ship_date'])\n",
    "\n",
    "\n",
    "data['day_of_week'] = data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "data['week_number'] = data['ship_date'].dt.week\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "data_filtered = data[data['day_of_week'].isin(desired_day_order)]\n",
    "\n",
    "# Pivot the data to count unique product IDs for each day of the week, week, and warehouse\n",
    "pivot_data = data_filtered.pivot_table(index=['whse', 'week_number'], columns='day_of_week', values='product_id', aggfunc='nunique', fill_value=0)\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task03_unique_product_ids_per_day_per_week_per_warehouse.xlsx')\n",
    "\n",
    "data_grouped = pivot_data.groupby('whse').sum()\n",
    "\n",
    "\n",
    "\n",
    "num_weeks = data['week_number'].nunique()\n",
    "\n",
    "data_grouped_average = data_grouped.div(num_weeks)\n",
    "\n",
    "\n",
    "#data_grouped.to_excel('2023_08_18_Task03_total_unique_product_ids_per_week_per_warehouse.xlsx')\n",
    "\n",
    "data_grouped_average.to_excel('2023_08_18_Task03_average_unique_product_ids_per_week_per_warehouse.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['route', 'ship_date', 'truck_id', 'old_truck_id', 'branch', 'whse',\n",
      "       'ShipFromAddress1', 'ShipToName2', 'ShipToAddress1', 'unique_del_loc',\n",
      "       'whse-acct-shipto', 'product_id', 'product_desc', 'uom', 'product_type',\n",
      "       'group_product_type', 'sub_product_type', 'product_line',\n",
      "       'product_line_desc', 'gallons_shipped', 'source', 'week',\n",
      "       'gallon_range', 'day_of_week', 'week_number'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-831f9a316492>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
      "<ipython-input-11-831f9a316492>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
      "<ipython-input-11-831f9a316492>:13: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n",
      "<ipython-input-11-831f9a316492>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "bulk_data = data[data['product_type'] == 'BULK']\n",
    "\n",
    "\n",
    "bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "bulk_data_filtered = bulk_data[bulk_data['day_of_week'].isin(desired_day_order)]\n",
    "\n",
    "pivot_data = bulk_data_filtered.pivot_table(index=['whse', 'week_number'], columns='day_of_week', values='product_id', aggfunc='nunique', fill_value=0)\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task04_unique_bulk_product_ids_per_day_per_week_per_warehouse.xlsx')\n",
    "\n",
    "\n",
    "data_grouped = pivot_data.groupby('whse').sum()\n",
    "\n",
    "\n",
    "\n",
    "num_weeks = data['week_number'].nunique()\n",
    "\n",
    "data_grouped_average = data_grouped.div(num_weeks)\n",
    "\n",
    "\n",
    "#data_grouped.to_excel('2023_08_18_Task03_total_unique_product_ids_per_week_per_warehouse.xlsx')\n",
    "\n",
    "data_grouped_average.to_excel('2023_08_18_Task04_average_bulk_product_ids_per_week_per_warehouse.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-70904728184a>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
      "<ipython-input-12-70904728184a>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
      "<ipython-input-12-70904728184a>:13: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n",
      "<ipython-input-12-70904728184a>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bulk_data = data[data['product_type'] == 'PACKAGE']\n",
    "\n",
    "\n",
    "bulk_data['ship_date'] = pd.to_datetime(bulk_data['ship_date'])\n",
    "\n",
    "\n",
    "bulk_data['day_of_week'] = bulk_data['ship_date'].dt.day_name()\n",
    "\n",
    "\n",
    "bulk_data['week_number'] = bulk_data['ship_date'].dt.week\n",
    "\n",
    "desired_day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "bulk_data_filtered = bulk_data[bulk_data['day_of_week'].isin(desired_day_order)]\n",
    "\n",
    "\n",
    "pivot_data = bulk_data_filtered.pivot_table(index=['whse', 'week_number'], columns='day_of_week', values='product_id', aggfunc='nunique', fill_value=0)\n",
    "\n",
    "\n",
    "pivot_data.to_excel('2023_08_18_Task05_unique_package_product_ids_per_day_per_week_per_warehouse.xlsx')\n",
    "\n",
    "data_grouped = pivot_data.groupby('whse').sum()\n",
    "\n",
    "\n",
    "\n",
    "num_weeks = data['week_number'].nunique()\n",
    "\n",
    "data_grouped_average = data_grouped.div(num_weeks)\n",
    "\n",
    "\n",
    "#data_grouped.to_excel('2023_08_18_Task03_total_unique_product_ids_per_week_per_warehouse.xlsx')\n",
    "\n",
    "data_grouped_average.to_excel('2023_08_18_Task05_average_package_product_ids_per_week_per_warehouse.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "grouped_data = data.groupby(['whse', 'product_id'])['gallons_shipped'].sum()\n",
    "\n",
    "\n",
    "grouped_data = grouped_data.reset_index()\n",
    "\n",
    "\n",
    "sorted_data = grouped_data.sort_values(by='gallons_shipped', ascending=False)\n",
    "\n",
    "\n",
    "top_products_per_warehouse = sorted_data.groupby('whse').head(5)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "top_products_per_warehouse.to_excel('2023_08_18_Task06_top_products_per_warehouse.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_data = data.groupby(['whse', 'product_id']).agg({\n",
    "    'gallons_shipped': 'sum',\n",
    "    'product_line': 'first',\n",
    "    'product_desc': 'first',\n",
    "    'product_line_desc': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "sorted_data = grouped_data.sort_values(by='gallons_shipped', ascending=False)\n",
    "\n",
    "top_products_per_warehouse = sorted_data.groupby('whse').head(5)\n",
    "\n",
    "top_products_per_warehouse.to_excel('2023_08_18_Task06_top_products_per_warehouse_extend.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
